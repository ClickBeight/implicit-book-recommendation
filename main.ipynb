{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Summary of Amazon Data\\n- Books from books_data.csv and Books_rating are connected via title\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import implicit\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"archive\"\n",
    "\n",
    "ratings_df = pd.read_csv(\n",
    "    f\"{data_dir}/Books_rating.csv\",\n",
    ")  # ~1.15 mio samples\n",
    "books_df = pd.read_csv(f\"{data_dir}/books_data.csv\")  # ~271 k samples\n",
    "\n",
    "title_to_index = {title: idx for idx, title in enumerate(books_df[\"Title\"].unique())} # covers all isbns from books\n",
    "user_to_index = {user: idx for idx, user in enumerate(ratings_df[\"User_id\"].unique())} # covers all users from ratings\n",
    "\n",
    "# create indices of books in df\n",
    "ratings_df[\"title_idx\"] = ratings_df[\"Title\"].map(title_to_index) \n",
    "books_df[\"title_idx\"] = books_df[\"Title\"].map(title_to_index)\n",
    "\n",
    "# create indices of users in df\n",
    "ratings_df[\"user_idx\"] = ratings_df[\"User_id\"].map(user_to_index) \n",
    "\n",
    "\"\"\"Summary of Kaggle Data\n",
    "- Books.csv contains all books rated in Ratings.csv, format: ISBN, Book-Title, Book-Author, ...\n",
    "- Ratings.csv contains all ratings, format: user_id, isbn, rating\n",
    "- Users.csv contains information about the users linked to ratings, format: User-ID, Location, Age\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"Summary of Amazon Data\n",
    "- Books from books_data.csv and Books_rating are connected via title\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sparse user-item matrix\n",
    "row_indices = ratings_df[\"user_idx\"].values\n",
    "col_indices = ratings_df[\"title_idx\"].values\n",
    "data = ratings_df[\"review/score\"].values\n",
    "\n",
    "# compressed sparse row matrix, as desired by `implicit`\n",
    "sparse_user_item_matrix = csr_matrix(\n",
    "    (data, (row_indices, col_indices)), shape=(len(user_to_index), len(title_to_index))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:34<00:00,  6.30s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Training complete'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(factors=50)\n",
    "model.fit(sparse_user_item_matrix)\n",
    "\"Training complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_recommendations(title, n=5):\n",
    "    title_idx = title_to_index[title]\n",
    "    similar_items, scores = model.similar_items(title_idx, n)  # returns ([*idxs], [*scores])\n",
    "    recommendations = [\n",
    "        books_df[books_df[\"title_idx\"] == idx] for idx in similar_items\n",
    "    ]\n",
    "    return recommendations, scores\n",
    "\n",
    "def compute_recommendation_score(title1, title2):\n",
    "    title_idx_1 = title_to_index[title1]\n",
    "    title_idx_2 = title_to_index[title2]\n",
    "\n",
    "    embedding_1 = model.item_factors[title_idx_1]\n",
    "    embedding_2 = model.item_factors[title_idx_2]\n",
    "\n",
    "    similarity = float(np.dot(embedding_1, embedding_2) / (np.linalg.norm(embedding_1) * np.linalg.norm(embedding_2)))\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Retraced',\n",
       " [('Retraced', 0.9999998807907104),\n",
       "  ('The Looking Heart: Poetic Expressions from Within', 0.9999772310256958),\n",
       "  ('Reborn', 0.9999348521232605),\n",
       "  ('The Language of Saxophones : Selected Poems of Kamau Daood',\n",
       "   0.9998949766159058),\n",
       "  ('A Brownstone in Brooklyn', 0.9998934268951416)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass a random book from Books.csv and return similar books\n",
    "book_title = random.choice(list(title_to_index.keys()))\n",
    "\n",
    "recommendations, scores = get_book_recommendations(book_title)\n",
    "\n",
    "book_title = books_df[books_df[\"Title\"] == book_title]\n",
    "book_title = book_title[\"Title\"].values[0]\n",
    "similar_books_formatted = [\n",
    "    (similar_book[\"Title\"].values[0], float(sim))\n",
    "    for similar_book, sim in zip(recommendations, scores)\n",
    "]\n",
    "\n",
    "book_title, similar_books_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Harry Potter and The Sorcerer's Stone\",\n",
       " [(\"Harry Potter and The Sorcerer's Stone\", 1.0),\n",
       "  ('God and Production in a Guatemalan Town (Texas Pan American Series)',\n",
       "   0.9941427111625671),\n",
       "  ('50 Hikes in Central Florida: Hikes, Walks, and Backpacks in the Heart of the Peninsula',\n",
       "   0.9939441680908203),\n",
       "  ('The Usborne History of the Twentieth Century (History of the Modern World)',\n",
       "   0.9936173558235168),\n",
       "  (\"Killer Clown of King's County (Bone Chillers)\", 0.9936156272888184)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return books similar to Harry Potter 1 by J. K. Rowling\n",
    "book_title = \"Harry Potter and The Sorcerer's Stone\"\n",
    "\n",
    "recommendations = get_book_recommendations(book_title)\n",
    "\n",
    "hp_1 = books_df[books_df[\"Title\"] == book_title]\n",
    "hp_1_title = hp_1[\"Title\"].values[0]\n",
    "recommendations = [\n",
    "    (book[\"Title\"].values[0], float(sim)) for book, sim in zip(*recommendations)\n",
    "]\n",
    "hp_1_title, recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NEW EARTH',\n",
       " [('NEW EARTH', 1.0000001192092896),\n",
       "  ('The book of woodcraft', 0.9984115362167358),\n",
       "  ('The book of woodcraft,: With 500 drawings,', 0.9984114766120911),\n",
       "  ('Larousse Pocket Student Dictionary French-English/ English-French (French Edition)',\n",
       "   0.9980927109718323),\n",
       "  ('Poker Secrets From Poker Champs DVD', 0.9980213642120361)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return books similar to The Power Of Now by Eckhart Tolle\n",
    "book_title = \"NEW EARTH\"\n",
    "\n",
    "recommendations = get_book_recommendations(book_title)\n",
    "\n",
    "pon = books_df[books_df[\"Title\"] == book_title]\n",
    "pon_title = pon[\"Title\"].values[0]\n",
    "recommendations = [\n",
    "    (book[\"Title\"].values[0], float(sim)) for book, sim in zip(*recommendations)\n",
    "]\n",
    "pon_title, recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9364229440689087\n",
      "0.14312927424907684\n",
      "0.04937087371945381\n",
      "0.18868790566921234\n"
     ]
    }
   ],
   "source": [
    "# compare HP 1 to HP 2 (expecting high similarity)\n",
    "hp_1 = \"Harry Potter and The Sorcerer's Stone\"\n",
    "hp_2 = \"Harry Potter and the Chamber of Secrets\"\n",
    "\n",
    "similarity = compute_recommendation_score(hp_1, hp_2)\n",
    "print(similarity)\n",
    "\n",
    "# compare HP 1 to LOTR (expecting moderate similarity)\n",
    "lotr = \"The Fellowship of the Ring\"\n",
    "similarity = compute_recommendation_score(hp_1, lotr)\n",
    "print(similarity)\n",
    "\n",
    "# compare HP 1 to New Earth (expecting low similarity)\n",
    "new_earth = \"NEW EARTH\"\n",
    "similarity = compute_recommendation_score(hp_1, new_earth)\n",
    "print(similarity)\n",
    "\n",
    "# compare How to Win Friends and Influence People to Seven Habits of Highly Effective People (expecting high similarity)\n",
    "htwf = 'How to Win Friends & Influence People (Cardinal Editions, C 303)'\n",
    "seven_habits = \"The 7 Habits of Highly Effective People (50 card deck)\"\n",
    "similarity = compute_recommendation_score(htwf, seven_habits)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/kwksxbdd0wd0x0hjzrpjw1tc0000gq/T/ipykernel_5023/1564390420.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  latent_factors_df[\"embedding\"] = latent_factors_df[\"ISBN\"].map(isbn_to_embedding)\n"
     ]
    }
   ],
   "source": [
    "# create new .csv with isbn, title, author, embedding\n",
    "item_factors = model.item_factors\n",
    "isbn_to_embedding = {\n",
    "    isbn: item_factors[title_to_index[isbn]]\n",
    "    for isbn in title_to_index.keys()\n",
    "}\n",
    "latent_factors_df = books_df[[\"Title\", \"authors\"]]\n",
    "latent_factors_df[\"embedding\"] = latent_factors_df[\"Title\"].map(isbn_to_embedding)\n",
    "\n",
    "# save books_with_embeddings.csv\n",
    "latent_factors_df.to_csv(f\"{data_dir}/books_with_embeddings.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
